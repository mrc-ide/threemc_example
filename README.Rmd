---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# threemc_example

We've noticed that when running TMB, system memory is spiking during tape optimisation and we would like to understand why. This is causing some problems for running model for large countries as it means we need to run on a machine with > 500GB of memory. This amount of memory is only used for a small period of the model fit and the rest of the fit continues. We're trying to understand

* Why does the memory spike like this?
* Can we predict the size of the memory spike from size in input data, number of parameters etc.
* Can we save out the optimised tape and then use this for multiple model fits? This could allow us to do the costly optimisation on a beefy node but then run the rest of the simulation on smaller nodes.

This repo contains an example of a smaller model fit which can be run with about 11GB of RAM but still shows the large spike during optimisation.

## Prerequisites

`readr`, `sf`, `TMB` and `threemc` packages

Install threemc from github
```r
remotes::install_github("mrc-ide/threemc")
```

## Running

Run the script from the command line via `./script.R`

or from R with working dir set to root of this repo
```r
source("threemc_fit.R")
threemc_fit()
```

## Profile

Run with profile from [memprof](https://github.com/mrc-ide/memprof)

```{r}
source("threemc_fit.R")
# load shell dataset
shell_dat <- readr::read_csv("data/shell_data_lso.csv.gz")
# load shapefiles
areas <- sf::read_sf("data/areas.geojson")
# load text from C++ mod into R
mod <- readLines("src/threemc.cpp")
mem <- memprof::with_monitor(threemc_fit(shell_dat, areas, mod))
plot(mem)
```

## Cluster Example 

The above example is for a small country, that can be run locally. However, 
when we look at modelling a large country, such as Ghana, we must run the model 
on a high performance cluster. The spike in memory shown above can even 
exceed 500GB. 
```{r}
# load shell dataset for Ghana
shell_dat_gha <- readr::read_csv("data/shell_data_gha.csv.gz")
```

```{r, results = "false"}
# specify directory that 
root <- "~/net/unaids-naomi/threemc-orderly/contexts_4"

# cluster config
config <- didehpc::didehpc_config(
  workdir  = root,
  cluster  = "fi--didemrchnb", 
  # need to request every core of largest cluster nodes in order to fit model
  # => at lower memory usage we could be running much more concurrent models!
  template = "32Core",        
  cores    = 32
)

# create symlink in cluster contexts dir to sourced functions
source_file <- file.path(root, "threemc_fit.R")
if (.Platform$OS.type != "windows" && !file.exists(source_file)) {
  system(paste0("ln -s threemc_fit.R ", source_file))
}

# setup context for orderly task 
ctx <- context::context_save(
  path = root,
  # functions to source in current directory
  sources = "./threemc_fit.R",
  # CRAN packages
  packages = c("dplyr", "sf", "readr", "TMB", "stats"),
  # packages from github 
  package_sources = conan::conan_sources(c(
    "github::mrc-ide/threemc", 
    "github::mrc-ide/memprof"
  ))
)
# queue above contexts
obj <- didehpc::queue_didehpc(context = ctx, config = config)
```

Running our model for Ghana, we can see how the memory spike scales up 
significantly as a result of the need for additional random effects in larger 
countries. 
```{r}
# profile memory usage
t <- obj$enqueue(
  memory_use(memprof::with_monitor(threemc_fit(shell_dat_gha, areas, mod)))
)
while (!t$status() %in% c("COMPLETE", "ERROR")) {
  Sys.sleep(15)
}

# plot result
res <- t$result()
plot(res)
```

```





